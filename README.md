# Decoder_Only_Transformer
This repo is coded with python and I coded in scatch of GPT architecture which is used Decoder-Only Transformer architecture.
I also using Bert embedding in this Transformer.

for running and training:
for training you should first preprocessing your dataset and then use it in decoder_only_transformer_trainer.py file and you can change the parameters too.
and for start training you should have a GPU and high performance for training. 
for chating you should run GPT_Chatbot.py.
